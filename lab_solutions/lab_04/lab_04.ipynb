{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04 - Bayesian Fitting\n",
    "## Tasks\n",
    "- Construct a Gaussian Process model and tune hyperparameters of GP model given noisy data\n",
    "- Investigate what kernels can be used to best represent the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/uspas/2021_optimization_and_ml --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#matplotlib graphs will be included in your notebook, next to the code:\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "We are going to look at some data that was generated by sampling a 5 x 5 x 5 grid in the domain [0,1] on each axis. The function that generated this data is\n",
    "\n",
    "$$\n",
    "f(x_1,x_2,x_3) = \\sin(2\\pi x_1)\\sin(\\pi x_2) + x_3\n",
    "$$\n",
    "\n",
    "The columns of the imported array is $(x_1,x_2,x_3,f)$. We need to convert it to a torch tensor to use with GPyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,5)\n",
    "xx = np.meshgrid(x,x,x)\n",
    "train_x = np.vstack([ele.ravel() for ele in xx]).T\n",
    "train_f = np.sin(2*np.pi*train_x[:,0]) * np.sin(np.pi*train_x[:,1]) + train_x[:,2] + np.random.randn(train_x.shape[0]) * 0.01\n",
    "\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_f = torch.from_numpy(train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a GP Model\n",
    "Here we define an Exact GP model using GPyTorch. The model is exact because we have analytic expressions for the integrals associated with the GP likelihood and output distribution. If we had a non-Gaussian likelihood or some other complication that prevented analytic integration we can also use Variational/Approximate/MCMC techniques to approximate the integrals necessary.\n",
    "\n",
    "Taking a close look at the model below we see two important modules:\n",
    "- ```self.mean_module``` which represents the mean function\n",
    "- ```self.covar_module``` which represents the kernel function (or what is used to calculate the kernel matrix\n",
    "\n",
    "Both of these objects are torch.nn.Module objects (see https://pytorch.org/docs/stable/generated/torch.nn.Module.html). PyTorch modules have trainable parameters which we can access when doing training. By grouping the modules inside another PyTorch module (gpytorch.models.ExactGP) lets us easily control which parameters are trained and which are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_f, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_f, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize our model with the training data and a defined likelihood (also a nn.Module) with a trainable noise parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_f, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: All PyTorch modules (including ExactGPModel) have ```.train()``` and ```.eval()``` modes. ```train()``` mode is for optimizing model hyperameters. ```.eval()``` mode is for computing predictions through the model posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Here we train the hyperparameters of the model (the parameters of the covar_module and the mean_module) to maximize the marginal log likelihood (minimize the negative marginal log likelihood). Note that since everything is defined in pyTorch we can use Autograd functionality to get the derivatives which will speed up optimization using the modified gradient descent algorithm ADAM.\n",
    "\n",
    "Also note that several of these hyperparameters (lengthscale and noise) must be strictly positive. Since ADAM is an unconstrained optimizer (which optimizes over the domain (-inf, inf)) gpytorch accounts for this constraint by optimizing the log of the lengthscale (raw_lengthscale). To get the actual lengthscale just use ```model.covar_module.base_kernel.lengthscale.item()```\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** \n",
    "    Write the steps for minimizing the negative log likelihood using pytorch. Refer back to Lab 3 for a reminder of how to do this. Use `gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)` as the loss function (which we are trying to maximize!). Use your function to train the model and report the marginal log likelihood.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, likelihood):\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    ################################################################\n",
    "    #ANSWER KEY - GPyTorch Training\n",
    "    ################################################################\n",
    "\n",
    "    #set training iterations\n",
    "    training_iter = 100\n",
    "\n",
    "    #print the trainable parameters\n",
    "    for param in model.named_parameters():\n",
    "        print(f'{param[0]} : {param[1]}')\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_f)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f  noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    #print the new trainable parameters\n",
    "    for param in model.named_parameters():\n",
    "        print(f'{param[0]} : {param[1]}')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.noise_covar.raw_noise : Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "mean_module.constant : Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "covar_module.raw_outputscale : 0.0\n",
      "covar_module.base_kernel.raw_lengthscale : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "Iter 1/100 - Loss: 0.925  noise: 0.693\n",
      "Iter 2/100 - Loss: 0.891  noise: 0.644\n",
      "Iter 3/100 - Loss: 0.858  noise: 0.598\n",
      "Iter 4/100 - Loss: 0.826  noise: 0.554\n",
      "Iter 5/100 - Loss: 0.796  noise: 0.513\n",
      "Iter 6/100 - Loss: 0.766  noise: 0.474\n",
      "Iter 7/100 - Loss: 0.738  noise: 0.438\n",
      "Iter 8/100 - Loss: 0.711  noise: 0.403\n",
      "Iter 9/100 - Loss: 0.685  noise: 0.372\n",
      "Iter 10/100 - Loss: 0.661  noise: 0.342\n",
      "Iter 11/100 - Loss: 0.639  noise: 0.314\n",
      "Iter 12/100 - Loss: 0.619  noise: 0.289\n",
      "Iter 13/100 - Loss: 0.600  noise: 0.265\n",
      "Iter 14/100 - Loss: 0.583  noise: 0.244\n",
      "Iter 15/100 - Loss: 0.568  noise: 0.224\n",
      "Iter 16/100 - Loss: 0.556  noise: 0.207\n",
      "Iter 17/100 - Loss: 0.545  noise: 0.191\n",
      "Iter 18/100 - Loss: 0.537  noise: 0.176\n",
      "Iter 19/100 - Loss: 0.532  noise: 0.163\n",
      "Iter 20/100 - Loss: 0.528  noise: 0.152\n",
      "Iter 21/100 - Loss: 0.527  noise: 0.142\n",
      "Iter 22/100 - Loss: 0.528  noise: 0.134\n",
      "Iter 23/100 - Loss: 0.530  noise: 0.127\n",
      "Iter 24/100 - Loss: 0.533  noise: 0.122\n",
      "Iter 25/100 - Loss: 0.536  noise: 0.117\n",
      "Iter 26/100 - Loss: 0.539  noise: 0.114\n",
      "Iter 27/100 - Loss: 0.541  noise: 0.112\n",
      "Iter 28/100 - Loss: 0.541  noise: 0.111\n",
      "Iter 29/100 - Loss: 0.541  noise: 0.110\n",
      "Iter 30/100 - Loss: 0.539  noise: 0.111\n",
      "Iter 31/100 - Loss: 0.536  noise: 0.112\n",
      "Iter 32/100 - Loss: 0.532  noise: 0.114\n",
      "Iter 33/100 - Loss: 0.527  noise: 0.116\n",
      "Iter 34/100 - Loss: 0.520  noise: 0.118\n",
      "Iter 35/100 - Loss: 0.511  noise: 0.121\n",
      "Iter 36/100 - Loss: 0.500  noise: 0.123\n",
      "Iter 37/100 - Loss: 0.485  noise: 0.126\n",
      "Iter 38/100 - Loss: 0.466  noise: 0.127\n",
      "Iter 39/100 - Loss: 0.443  noise: 0.128\n",
      "Iter 40/100 - Loss: 0.417  noise: 0.127\n",
      "Iter 41/100 - Loss: 0.393  noise: 0.125\n",
      "Iter 42/100 - Loss: 0.375  noise: 0.122\n",
      "Iter 43/100 - Loss: 0.367  noise: 0.118\n",
      "Iter 44/100 - Loss: 0.365  noise: 0.112\n",
      "Iter 45/100 - Loss: 0.360  noise: 0.106\n",
      "Iter 46/100 - Loss: 0.342  noise: 0.099\n",
      "Iter 47/100 - Loss: 0.313  noise: 0.093\n",
      "Iter 48/100 - Loss: 0.280  noise: 0.086\n",
      "Iter 49/100 - Loss: 0.248  noise: 0.079\n",
      "Iter 50/100 - Loss: 0.224  noise: 0.072\n",
      "Iter 51/100 - Loss: 0.206  noise: 0.066\n",
      "Iter 52/100 - Loss: 0.191  noise: 0.060\n",
      "Iter 53/100 - Loss: 0.172  noise: 0.055\n",
      "Iter 54/100 - Loss: 0.145  noise: 0.050\n",
      "Iter 55/100 - Loss: 0.115  noise: 0.045\n",
      "Iter 56/100 - Loss: 0.085  noise: 0.041\n",
      "Iter 57/100 - Loss: 0.063  noise: 0.037\n",
      "Iter 58/100 - Loss: 0.048  noise: 0.033\n",
      "Iter 59/100 - Loss: 0.031  noise: 0.030\n",
      "Iter 60/100 - Loss: 0.009  noise: 0.027\n",
      "Iter 61/100 - Loss: -0.018  noise: 0.025\n",
      "Iter 62/100 - Loss: -0.044  noise: 0.022\n",
      "Iter 63/100 - Loss: -0.064  noise: 0.020\n",
      "Iter 64/100 - Loss: -0.079  noise: 0.018\n",
      "Iter 65/100 - Loss: -0.098  noise: 0.016\n",
      "Iter 66/100 - Loss: -0.122  noise: 0.015\n",
      "Iter 67/100 - Loss: -0.145  noise: 0.013\n",
      "Iter 68/100 - Loss: -0.163  noise: 0.012\n",
      "Iter 69/100 - Loss: -0.178  noise: 0.011\n",
      "Iter 70/100 - Loss: -0.197  noise: 0.010\n",
      "Iter 71/100 - Loss: -0.218  noise: 0.009\n",
      "Iter 72/100 - Loss: -0.237  noise: 0.008\n",
      "Iter 73/100 - Loss: -0.252  noise: 0.007\n",
      "Iter 74/100 - Loss: -0.267  noise: 0.007\n",
      "Iter 75/100 - Loss: -0.285  noise: 0.006\n",
      "Iter 76/100 - Loss: -0.302  noise: 0.006\n",
      "Iter 77/100 - Loss: -0.316  noise: 0.005\n",
      "Iter 78/100 - Loss: -0.329  noise: 0.005\n",
      "Iter 79/100 - Loss: -0.345  noise: 0.004\n",
      "Iter 80/100 - Loss: -0.360  noise: 0.004\n",
      "Iter 81/100 - Loss: -0.371  noise: 0.004\n",
      "Iter 82/100 - Loss: -0.383  noise: 0.003\n",
      "Iter 83/100 - Loss: -0.397  noise: 0.003\n",
      "Iter 84/100 - Loss: -0.409  noise: 0.003\n",
      "Iter 85/100 - Loss: -0.419  noise: 0.003\n",
      "Iter 86/100 - Loss: -0.430  noise: 0.002\n",
      "Iter 87/100 - Loss: -0.441  noise: 0.002\n",
      "Iter 88/100 - Loss: -0.451  noise: 0.002\n",
      "Iter 89/100 - Loss: -0.460  noise: 0.002\n",
      "Iter 90/100 - Loss: -0.470  noise: 0.002\n",
      "Iter 91/100 - Loss: -0.479  noise: 0.002\n",
      "Iter 92/100 - Loss: -0.487  noise: 0.002\n",
      "Iter 93/100 - Loss: -0.495  noise: 0.001\n",
      "Iter 94/100 - Loss: -0.503  noise: 0.001\n",
      "Iter 95/100 - Loss: -0.510  noise: 0.001\n",
      "Iter 96/100 - Loss: -0.517  noise: 0.001\n",
      "Iter 97/100 - Loss: -0.524  noise: 0.001\n",
      "Iter 98/100 - Loss: -0.530  noise: 0.001\n",
      "Iter 99/100 - Loss: -0.536  noise: 0.001\n",
      "Iter 100/100 - Loss: -0.542  noise: 0.001\n",
      "likelihood.noise_covar.raw_noise : Parameter containing:\n",
      "tensor([-7.1395], requires_grad=True)\n",
      "mean_module.constant : Parameter containing:\n",
      "tensor([0.4748], requires_grad=True)\n",
      "covar_module.raw_outputscale : 0.7010450959205627\n",
      "covar_module.base_kernel.raw_lengthscale : Parameter containing:\n",
      "tensor([[-0.6373]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "nmll = train_model(model, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task:** \n",
    "    Define a new GP model that uses a different kernel (or combination of kernels) to maximize the marginal log likelihood.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_f, likelihood):\n",
    "        super(MyExactGPModel, self).__init__(train_x, train_f, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        \n",
    "        ################################################################\n",
    "        #ANSWER KEY - GPyTorch New Kernel - NOTE you can also use CosKernel()\n",
    "        ################################################################\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                                gpytorch.kernels.PeriodicKernel(active_dims = 0) *\\\n",
    "                                gpytorch.kernels.PeriodicKernel(active_dims = 1)) +\\\n",
    "                                gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel(active_dims = 2))\n",
    "                                                        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.noise_covar.raw_noise : Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "mean_module.constant : Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "covar_module.kernels.0.raw_outputscale : 0.0\n",
      "covar_module.kernels.0.base_kernel.kernels.0.raw_lengthscale : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.0.raw_period_length : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.1.raw_lengthscale : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.1.raw_period_length : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "covar_module.kernels.1.raw_outputscale : 0.0\n",
      "covar_module.kernels.1.base_kernel.raw_variance : Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "Iter 1/100 - Loss: 0.930  noise: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/.pyenv/versions/py3/lib/python3.7/site-packages/gpytorch/utils/cholesky.py:83: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2/100 - Loss: 0.892  noise: 0.644\n",
      "Iter 3/100 - Loss: 0.860  noise: 0.598\n",
      "Iter 4/100 - Loss: 0.820  noise: 0.555\n",
      "Iter 5/100 - Loss: 0.781  noise: 0.513\n",
      "Iter 6/100 - Loss: 0.742  noise: 0.474\n",
      "Iter 7/100 - Loss: 0.700  noise: 0.437\n",
      "Iter 8/100 - Loss: 0.652  noise: 0.403\n",
      "Iter 9/100 - Loss: 0.610  noise: 0.370\n",
      "Iter 10/100 - Loss: 0.573  noise: 0.340\n",
      "Iter 11/100 - Loss: 0.531  noise: 0.311\n",
      "Iter 12/100 - Loss: 0.486  noise: 0.285\n",
      "Iter 13/100 - Loss: 0.439  noise: 0.261\n",
      "Iter 14/100 - Loss: 0.391  noise: 0.238\n",
      "Iter 15/100 - Loss: 0.344  noise: 0.217\n",
      "Iter 16/100 - Loss: 0.300  noise: 0.198\n",
      "Iter 17/100 - Loss: 0.260  noise: 0.180\n",
      "Iter 18/100 - Loss: 0.221  noise: 0.163\n",
      "Iter 19/100 - Loss: 0.178  noise: 0.148\n",
      "Iter 20/100 - Loss: 0.133  noise: 0.134\n",
      "Iter 21/100 - Loss: 0.089  noise: 0.122\n",
      "Iter 22/100 - Loss: 0.049  noise: 0.110\n",
      "Iter 23/100 - Loss: 0.008  noise: 0.100\n",
      "Iter 24/100 - Loss: -0.035  noise: 0.090\n",
      "Iter 25/100 - Loss: -0.081  noise: 0.082\n",
      "Iter 26/100 - Loss: -0.125  noise: 0.074\n",
      "Iter 27/100 - Loss: -0.166  noise: 0.067\n",
      "Iter 28/100 - Loss: -0.211  noise: 0.060\n",
      "Iter 29/100 - Loss: -0.259  noise: 0.054\n",
      "Iter 30/100 - Loss: -0.302  noise: 0.049\n",
      "Iter 31/100 - Loss: -0.346  noise: 0.044\n",
      "Iter 32/100 - Loss: -0.394  noise: 0.040\n",
      "Iter 33/100 - Loss: -0.438  noise: 0.036\n",
      "Iter 34/100 - Loss: -0.483  noise: 0.032\n",
      "Iter 35/100 - Loss: -0.531  noise: 0.029\n",
      "Iter 36/100 - Loss: -0.575  noise: 0.026\n",
      "Iter 37/100 - Loss: -0.624  noise: 0.024\n",
      "Iter 38/100 - Loss: -0.668  noise: 0.021\n",
      "Iter 39/100 - Loss: -0.717  noise: 0.019\n",
      "Iter 40/100 - Loss: -0.757  noise: 0.017\n",
      "Iter 41/100 - Loss: -0.802  noise: 0.016\n",
      "Iter 42/100 - Loss: -0.851  noise: 0.014\n",
      "Iter 43/100 - Loss: -0.895  noise: 0.013\n",
      "Iter 44/100 - Loss: -0.934  noise: 0.011\n",
      "Iter 45/100 - Loss: -0.984  noise: 0.010\n",
      "Iter 46/100 - Loss: -1.027  noise: 0.009\n",
      "Iter 47/100 - Loss: -1.063  noise: 0.008\n",
      "Iter 48/100 - Loss: -1.119  noise: 0.007\n",
      "Iter 49/100 - Loss: -1.139  noise: 0.007\n",
      "Iter 50/100 - Loss: -1.182  noise: 0.006\n",
      "Iter 51/100 - Loss: -1.242  noise: 0.005\n",
      "Iter 52/100 - Loss: -1.264  noise: 0.005\n",
      "Iter 53/100 - Loss: -1.295  noise: 0.004\n",
      "Iter 54/100 - Loss: -1.337  noise: 0.004\n",
      "Iter 55/100 - Loss: -1.382  noise: 0.004\n",
      "Iter 56/100 - Loss: -1.445  noise: 0.003\n",
      "Iter 57/100 - Loss: -1.476  noise: 0.003\n",
      "Iter 58/100 - Loss: -1.500  noise: 0.003\n",
      "Iter 59/100 - Loss: -1.537  noise: 0.002\n",
      "Iter 60/100 - Loss: -1.575  noise: 0.002\n",
      "Iter 61/100 - Loss: -1.620  noise: 0.002\n",
      "Iter 62/100 - Loss: -1.674  noise: 0.002\n",
      "Iter 63/100 - Loss: -1.713  noise: 0.002\n",
      "Iter 64/100 - Loss: -1.737  noise: 0.002\n",
      "Iter 65/100 - Loss: -1.780  noise: 0.001\n",
      "Iter 66/100 - Loss: -1.852  noise: 0.001\n",
      "Iter 67/100 - Loss: -1.855  noise: 0.001\n",
      "Iter 68/100 - Loss: -1.892  noise: 0.001\n",
      "Iter 69/100 - Loss: -1.932  noise: 0.001\n",
      "Iter 70/100 - Loss: -1.975  noise: 0.001\n",
      "Iter 71/100 - Loss: -1.968  noise: 0.001\n",
      "Iter 72/100 - Loss: -1.985  noise: 0.001\n",
      "Iter 73/100 - Loss: -2.010  noise: 0.001\n",
      "Iter 74/100 - Loss: -2.029  noise: 0.001\n",
      "Iter 75/100 - Loss: -2.066  noise: 0.001\n",
      "Iter 76/100 - Loss: -2.094  noise: 0.001\n",
      "Iter 77/100 - Loss: -2.138  noise: 0.001\n",
      "Iter 78/100 - Loss: -2.172  noise: 0.000\n",
      "Iter 79/100 - Loss: -2.179  noise: 0.000\n",
      "Iter 80/100 - Loss: -2.215  noise: 0.000\n",
      "Iter 81/100 - Loss: -2.219  noise: 0.000\n",
      "Iter 82/100 - Loss: -2.223  noise: 0.000\n",
      "Iter 83/100 - Loss: -2.237  noise: 0.000\n",
      "Iter 84/100 - Loss: -2.254  noise: 0.000\n",
      "Iter 85/100 - Loss: -2.289  noise: 0.000\n",
      "Iter 86/100 - Loss: -2.299  noise: 0.000\n",
      "Iter 87/100 - Loss: -2.297  noise: 0.000\n",
      "Iter 88/100 - Loss: -2.309  noise: 0.000\n",
      "Iter 89/100 - Loss: -2.336  noise: 0.000\n",
      "Iter 90/100 - Loss: -2.339  noise: 0.000\n",
      "Iter 91/100 - Loss: -2.338  noise: 0.000\n",
      "Iter 92/100 - Loss: -2.348  noise: 0.000\n",
      "Iter 93/100 - Loss: -2.371  noise: 0.000\n",
      "Iter 94/100 - Loss: -2.371  noise: 0.000\n",
      "Iter 95/100 - Loss: -2.364  noise: 0.000\n",
      "Iter 96/100 - Loss: -2.383  noise: 0.000\n",
      "Iter 97/100 - Loss: -2.427  noise: 0.000\n",
      "Iter 98/100 - Loss: -2.383  noise: 0.000\n",
      "Iter 99/100 - Loss: -2.379  noise: 0.000\n",
      "Iter 100/100 - Loss: -2.373  noise: 0.000\n",
      "likelihood.noise_covar.raw_noise : Parameter containing:\n",
      "tensor([-9.3144], requires_grad=True)\n",
      "mean_module.constant : Parameter containing:\n",
      "tensor([-0.0024], requires_grad=True)\n",
      "covar_module.kernels.0.raw_outputscale : -1.4278644323349\n",
      "covar_module.kernels.0.base_kernel.kernels.0.raw_lengthscale : Parameter containing:\n",
      "tensor([[-0.4513]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.0.raw_period_length : Parameter containing:\n",
      "tensor([[0.5129]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.1.raw_lengthscale : Parameter containing:\n",
      "tensor([[2.9549]], requires_grad=True)\n",
      "covar_module.kernels.0.base_kernel.kernels.1.raw_period_length : Parameter containing:\n",
      "tensor([[0.5453]], requires_grad=True)\n",
      "covar_module.kernels.1.raw_outputscale : 0.5457532405853271\n",
      "covar_module.kernels.1.base_kernel.raw_variance : Parameter containing:\n",
      "tensor([[0.5458]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.3728, dtype=torch.float64, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################\n",
    "#ANSWER KEY - GPyTorch Training - New Kernel\n",
    "################################################################\n",
    "my_likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "my_model = MyExactGPModel(train_x, train_f, my_likelihood)\n",
    "train_model(my_model, my_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task:** \n",
    "    Plot the mean and uncertainty along the $x_1$ axis where $x_2=\\pi/2, x_3=0$.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: you can use the following code to get the predicted mean, lower + upper confidence bounds\n",
    "x = torch.zeros(1,3).double()\n",
    "my_likelihood.eval()\n",
    "my_model.eval()\n",
    "with torch.no_grad():\n",
    "    post = my_likelihood(my_model(x))\n",
    "    mean = post.mean\n",
    "    lower,upper = post.confidence_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f7a4178be10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################################################\n",
    "#ANSWER KEY - GPyTorch Training - New Kernel\n",
    "################################################################\n",
    "n = 100\n",
    "x_test = torch.zeros(n,3).double()\n",
    "x_test[:,0] = torch.linspace(0,1,n)\n",
    "x_test[:,1] = np.pi / 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    post = my_likelihood(my_model(x_test))\n",
    "    mean = post.mean\n",
    "    lower,upper = post.confidence_region()\n",
    "    \n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(x_test[:,0], mean)\n",
    "ax.fill_between(x_test[:,0],lower,upper,alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
